{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akalpit23/Explainable-techniques/blob/main/Assignment-6/Explainable_Techniques_Assignment_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvE9yaYHjHP5"
      },
      "source": [
        "# AIPI 590 - XAI | Assignment #06\n",
        "\n",
        "\n",
        "\n",
        "## Akalpit Dawkhar\n",
        "\n",
        "### **Explainable Techniques-2**\n",
        "\n",
        "### Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4nHtcanejHP7",
        "outputId": "f437cfd2-6dcb-43c4-9195-b9b2869b22eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Explainable-techniques'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 168 (delta 86), reused 93 (delta 37), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (168/168), 6.55 MiB | 9.10 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.5.0 Requires-Python >=3.6,<3.8; 0.5.1 Requires-Python >=3.6,<3.8\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement alepython (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for alepython\u001b[0m\u001b[31m\n",
            "\u001b[0m[Errno 2] No such file or directory: 'Explainable-techniques/Assignment-6/Assignment-6/'\n",
            "/content\n",
            "\u001b[0m\u001b[01;34mExplainable-techniques\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# Please use this to connect your GitHub repository to your Google Colab notebook\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"Explainable-techniques/Assignment-6/\" # Change to your repo name\n",
        "git_path = 'https://github.com/akalpit23/Explainable-techniques.git' #Change to your path\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "!pip install -q -r \"{os.path.join(repo_name,'requirements.txt')}\" #Add if using requirements.txt\n",
        "\n",
        "# Change working directory to location of notebook\n",
        "notebook_dir = 'Assignment-6/'\n",
        "path_to_notebook = os.path.join(repo_name,notebook_dir)\n",
        "%cd \"{path_to_notebook}\"\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDTCYkp0jHP8"
      },
      "source": [
        "# 1. Importing neccessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2zr1n7hgjHP8",
        "outputId": "e1e64a38-e9b8-458f-9f40-3c424ae65555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-Tk2aD1ijHP8",
        "outputId": "31866163-94ad-421b-bca4-2c6df43c28bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'alibi'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ab417775fe0a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPartialDependenceDisplay\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mpartial_dependence\u001b[0m \u001b[0;31m# Updated import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malibi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_ale\u001b[0m  \u001b[0;31m# Importing ALE and the correct plotting function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'alibi'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.inspection import PartialDependenceDisplay ,partial_dependence\n",
        "from alibi.explainers import ALE, plot_ale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqs-MZOajHP8"
      },
      "source": [
        "# 2. Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsV2iNr7jHP8"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load your dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQCH07B5jHP9"
      },
      "source": [
        "# 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOVlxeTtjHP9"
      },
      "outputs": [],
      "source": [
        "# Step 3: Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Convert categorical variables to numerical via one-hot encoding\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Drop rows with missing values for simplicity\n",
        "df_encoded = df_encoded.dropna()\n",
        "\n",
        "# Visualize correlation heatmap for numeric columns only\n",
        "plt.figure(figsize=(20,10))\n",
        "corr_matrix = df_encoded.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Data Preprocessing\n",
        "X = df_encoded.drop('survived', axis=1)  # Assuming \"survived\" is the target variable\n",
        "y = df_encoded['survived']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PLUpSM5jHP9"
      },
      "source": [
        "# 4. Model Selection and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0M4IcUJjHP9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNUv_3x3jHP9"
      },
      "source": [
        "# 5. Partial Dependance Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hlmuk7GjHP-"
      },
      "outputs": [],
      "source": [
        "# Define the features you want to visualize\n",
        "features = ['age', 'fare', 'who_man', 'who_woman', 'deck_B', 'deck_C', 'deck_D', 'deck_E', 'deck_F', 'deck_G', 'class_Second', 'class_Third']\n",
        "n_features = len(features)\n",
        "\n",
        "# Define the number of rows and columns for the plot grid\n",
        "n_rows = 4\n",
        "n_cols = 3\n",
        "\n",
        "# Create the figure with a grid of subplots\n",
        "plt.figure(figsize=(n_cols * 5, n_rows * 5))\n",
        "\n",
        "# Loop over the features to plot each partial dependence\n",
        "plot_idx = 1\n",
        "for feature in features:\n",
        "    # Create a subplot for each feature\n",
        "    plt.subplot(n_rows, n_cols, plot_idx)\n",
        "\n",
        "    # Compute the partial dependence for the given feature\n",
        "    pd_results = partial_dependence(model, X=X_test, features=[feature])\n",
        "\n",
        "    # Extract the grid of feature values and corresponding partial dependence values\n",
        "    grid_values = pd_results['values'][0]\n",
        "    pd_values = pd_results['average'][0]\n",
        "\n",
        "    # Plot the partial dependence\n",
        "    plt.plot(grid_values, pd_values, label='Partial Dependence')\n",
        "\n",
        "    # Use the feature name in the title and labels\n",
        "    plt.title(f\"Partial Dependence of {feature}\")\n",
        "    plt.ylabel('Partial Dependence')\n",
        "    plt.xlabel(feature)\n",
        "    plt.legend()\n",
        "\n",
        "    plot_idx += 1\n",
        "\n",
        "# Adjust the layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jLd_UsUjHP-"
      },
      "source": [
        "# 6. ALE Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoTtt3RdjHP-"
      },
      "outputs": [],
      "source": [
        "# ALE (Using alibi for ALE)\n",
        "ale_explainer = ALE(model.predict, feature_names=X_test.columns.tolist())\n",
        "ale_explanation = ale_explainer.explain(X_test.values)\n",
        "\n",
        "# Plot ALE for the first two features\n",
        "plot_ale(ale_explanation, features=[0, 1])  # Updated plotting function\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNP_jz4QjHP-"
      },
      "source": [
        "# 7. ICE plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5k4lXhnjHP-"
      },
      "outputs": [],
      "source": [
        "# Let's say we want to plot ICE for the first feature\n",
        "feature = X_test.columns[0]\n",
        "\n",
        "# Generate ICE data\n",
        "ice_df = ice(data=X_test, column=feature, predict=model.predict)\n",
        "\n",
        "# Create ICE plot\n",
        "ice_plot(ice_df, c='dimgray', linewidth=0.3)\n",
        "plt.ylabel('Model prediction')\n",
        "plt.xlabel('Feature value')\n",
        "plt.title('ICE plot for feature: {}'.format(feature))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvdPHQxPjHP_"
      },
      "outputs": [],
      "source": [
        "# Display model evaluation report (Optional)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsS311-ujHP_"
      },
      "outputs": [],
      "source": [
        "# Custom ICE Plot Implementation for 'age' Feature\n",
        "\n",
        "def plot_ice(model, X, feature_name, feature_range=None):\n",
        "    \"\"\"\n",
        "    Plots ICE curves for a specific feature by iterating through its range of values.\n",
        "    \"\"\"\n",
        "    if feature_range is None:\n",
        "        feature_range = np.linspace(X[feature_name].min(), X[feature_name].max(), num=50)\n",
        "\n",
        "    X_temp = X.copy()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        y_pred = []\n",
        "        for val in feature_range:\n",
        "            X_temp.loc[i, feature_name] = val\n",
        "            pred = model.predict_proba(X_temp.iloc[[i]])[:, 1]  # Probability for class 1\n",
        "            y_pred.append(pred[0])\n",
        "\n",
        "        plt.plot(feature_range, y_pred, color='gray', alpha=0.3)\n",
        "\n",
        "    plt.title(f\"ICE Plot for {feature_name}\")\n",
        "    plt.xlabel(feature_name)\n",
        "    plt.ylabel('Prediction')\n",
        "    plt.show()\n",
        "\n",
        "# Example of plotting ICE for the 'age' feature\n",
        "plot_ice(model, X_test, feature_name='age')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEPHxDhhjHP_"
      },
      "source": [
        "# 8. Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6c1TFjqjHP_"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}