{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akalpit23/Explainable-techniques/blob/main/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRp--YumqWdP"
      },
      "source": [
        "# AIPI 590 - XAI | Assignment #07\n",
        "\n",
        "\n",
        "\n",
        "## Akalpit Dawkhar\n",
        "\n",
        "### **Explainable_Deep_Learning**\n",
        "\n",
        "### Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOq8iJqDqWdR"
      },
      "outputs": [],
      "source": [
        "# Please use this to connect your GitHub repository to your Google Colab notebook\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"Explainable-techniques/Assignment-7/\" # Change to your repo name\n",
        "git_path = 'https://github.com/akalpit23/Explainable-techniques.git' #Change to your path\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "!pip install -q -r \"{os.path.join(repo_name,'requirements.txt')}\" #Add if using requirements.txt\n",
        "\n",
        "# Change working directory to location of notebook\n",
        "notebook_dir = 'Assignment-7/'\n",
        "path_to_notebook = os.path.join(repo_name,notebook_dir)\n",
        "%cd \"{path_to_notebook}\"\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy9T3QD4qWdT"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIl82_W5qWdT"
      },
      "source": [
        "# Hypothesis:\n",
        "\n",
        "Null Hypothesis (H0): The ResNet34 model does not show a significant difference in identifying the concept of \"roundness\" when applied to images of oranges compared to images of basketballs.\n",
        "\n",
        "Alternative Hypothesis (H1): The ResNet34 model shows a significant difference in identifying the concept of \"roundness\" when applied to images of oranges compared to images of basketballs, specifically, it better identifies \"roundness\" in oranges compared to basketballs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7oHUfPmqWdT",
        "outputId": "5c4274c9-d0ba-40be-bcd3-4d35956f9374"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/akalpitdawkhar/Desktop/School/SEM 3/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akalpitdawkhar/Desktop/School/SEM%203/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/akalpitdawkhar/Desktop/School/SEM%203/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akalpitdawkhar/Desktop/School/SEM%203/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akalpitdawkhar/Desktop/School/SEM%203/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import IntegratedGradients\n",
        "from tcav import TCAV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUrb1hQaqWdU"
      },
      "outputs": [],
      "source": [
        "# Step 1: Dataset Preparation\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Assuming images of oranges and basketballs are stored in './data/oranges' and './data/basketballs'\n",
        "dataset = ImageFolder(root='./data', transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw2_uaIZqWdU"
      },
      "outputs": [],
      "source": [
        "# Step 2: Model Selection\n",
        "model = models.resnet34(pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr3x6qH5qWdV"
      },
      "outputs": [],
      "source": [
        "# Step 3: TCAV Analysis\n",
        "# Placeholder for TCAV implementation - requires concepts and bottlenecks to be defined\n",
        "# Assuming we have defined bottlenecks and concept datasets\n",
        "tcav = TCAV(model, bottlenecks, concepts, target_class)\n",
        "tcav_scores = tcav.run()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUDVvWtuqWdV"
      },
      "outputs": [],
      "source": [
        "# Step 4: Integrated Gradients\n",
        "ig = IntegratedGradients(model)\n",
        "\n",
        "def visualize_integrated_gradients(input_image, target_class):\n",
        "    input_image = input_image.unsqueeze(0)\n",
        "    input_image.requires_grad = True\n",
        "    attributions, delta = ig.attribute(input_image, target=target_class, return_convergence_delta=True)\n",
        "    attributions = attributions.squeeze().cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(attributions, (1, 2, 0)))\n",
        "    plt.title('Integrated Gradients Attribution')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with an image from the validation set\n",
        "sample_image, sample_label = val_dataset[0]\n",
        "visualize_integrated_gradients(sample_image, sample_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XweNbVmWqWdV"
      },
      "outputs": [],
      "source": [
        "# Step 5: Statistical Testing\n",
        "# Placeholder for statistical testing of TCAV scores\n",
        "import scipy.stats as stats\n",
        "t_stat, p_value = stats.ttest_ind(tcav_scores_oranges, tcav_scores_basketballs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}