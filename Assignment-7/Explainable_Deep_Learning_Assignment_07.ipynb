{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akalpit23/Explainable-techniques/blob/main/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRp--YumqWdP"
      },
      "source": [
        "# AIPI 590 - XAI | Assignment #07\n",
        "\n",
        "\n",
        "\n",
        "## Akalpit Dawkhar\n",
        "\n",
        "### **Explainable_Deep_Learning**\n",
        "\n",
        "### Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOq8iJqDqWdR"
      },
      "outputs": [],
      "source": [
        "# Please use this to connect your GitHub repository to your Google Colab notebook\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"Explainable-techniques/Assignment-7/\" # Change to your repo name\n",
        "git_path = 'https://github.com/akalpit23/Explainable-techniques.git' #Change to your path\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "!pip install -q -r \"{os.path.join(repo_name,'requirements.txt')}\" #Add if using requirements.txt\n",
        "\n",
        "# Change working directory to location of notebook\n",
        "notebook_dir = 'Assignment-7/'\n",
        "path_to_notebook = os.path.join(repo_name,notebook_dir)\n",
        "%cd \"{path_to_notebook}\"\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy9T3QD4qWdT"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working with TCAV "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'Desktop/School/SEM_3/XAI/Explainable-techniques/Assignment-7/'\n",
            "/Users/akalpitdawkhar/Desktop/School/SEM_3/XAI/Explainable-techniques/Assignment-7\n",
            "Explainable_Deep_Learning_Assignment_07.ipynb\n",
            "requirements.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/akalpitdawkhar/Desktop/School/SEM_3/XAI/Explainable-techniques/.venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n"
          ]
        }
      ],
      "source": [
        "%cd Desktop/School/SEM_3/XAI/Explainable-techniques/Assignment-7/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTRIBUTING.md         README.md               requirements.txt\n",
            "FetchDataAndModels.sh   Run_TCAV.ipynb          setup.py\n",
            "LICENSE                 Run_TCAV_on_colab.ipynb \u001b[34mtcav\u001b[m\u001b[m\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/akalpitdawkhar/Desktop/School/SEM_3/XAI/Explainable-techniques/Assignment-7/tcav/tcav/tcav/tcav/tcav_examples/image_models/imagenet\n",
            "FetchDataAndModels.sh          download_and_make_datasets.py\n",
            "README.md                      imagenet_and_broden_fetcher.py\n",
            "__init__.py                    imagenet_url_map.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/akalpitdawkhar/Desktop/School/SEM_3/XAI/Explainable-techniques/.venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd tcav_examples/image_models/imagenet\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'tcav' already exists and is not an empty directory.\n",
            "/Users/akalpitdawkhar/Library/Mobile Documents/.Trash/tcav 9.42.00 PM/tcav/tcav/tcav/tcav_examples/image_models/imagenet/tcav/tcav\n",
            "__init__.py             model_test.py           tcav_test.py\n",
            "activation_generator.py run_params.py           utils.py\n",
            "cav.py                  tcav.py                 utils_plot.py\n",
            "cav_test.py             \u001b[34mtcav_examples\u001b[m\u001b[m           utils_test.py\n",
            "model.py                \u001b[34mtcav_results\u001b[m\u001b[m\n",
            "[Errno 2] No such file or directory: '/tcav/tcav_examples/image_models/imagenet'\n",
            "/Users/akalpitdawkhar/Library/Mobile Documents/.Trash/tcav 9.42.00 PM/tcav/tcav/tcav/tcav_examples/image_models/imagenet/tcav/tcav\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "File `'download_and_make_datasets.py'` not found.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "File \u001b[0;32m~/Desktop/School/SEM_3/XAI/Explainable-techniques/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:716\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    715\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 716\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Desktop/School/SEM_3/XAI/Explainable-techniques/.venv/lib/python3.12/site-packages/IPython/utils/path.py:91\u001b[0m, in \u001b[0;36mget_py_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
            "\u001b[0;31mOSError\u001b[0m: File `'download_and_make_datasets.py'` not found.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Next, we will create the datasets\u001b[39;00m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tcav/tcav_examples/image_models/imagenet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdownload_and_make_datasets.py --source_dir=YOUR_FOLDER --number_of_images_per_folder=10 --number_of_random_folders=10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/tcav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/School/SEM_3/XAI/Explainable-techniques/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[0;32m~/Desktop/School/SEM_3/XAI/Explainable-techniques/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:727\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[1;32m    726\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
            "\u001b[0;31mException\u001b[0m: File `'download_and_make_datasets.py'` not found."
          ]
        }
      ],
      "source": [
        "# We are going to clone the tcav repo in GitHub:\n",
        "!git clone https://github.com/tensorflow/tcav.git tcav\n",
        "%cd tcav\n",
        "!ls\n",
        "\n",
        "# Next, we will create the datasets\n",
        "%cd /tcav/tcav_examples/image_models/imagenet\n",
        "%run download_and_make_datasets.py --source_dir=YOUR_FOLDER --number_of_images_per_folder=10 --number_of_random_folders=10\n",
        "\n",
        "%cd /content/tcav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIl82_W5qWdT"
      },
      "source": [
        "# Hypothesis:\n",
        "\n",
        "Null Hypothesis (H0): The ResNet34 model does not show a significant difference in identifying the concept of \"roundness\" when applied to images of oranges compared to images of basketballs.\n",
        "\n",
        "Alternative Hypothesis (H1): The ResNet34 model shows a significant difference in identifying the concept of \"roundness\" when applied to images of oranges compared to images of basketballs, specifically, it better identifies \"roundness\" in oranges compared to basketballs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7oHUfPmqWdT",
        "outputId": "5c4274c9-d0ba-40be-bcd3-4d35956f9374"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/akalpitdawkhar/Desktop/School/SEM 3/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akalpitdawkhar/Desktop/School/SEM%203/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/akalpitdawkhar/Desktop/School/SEM%203/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akalpitdawkhar/Desktop/School/SEM%203/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akalpitdawkhar/Desktop/School/SEM%203/XAI/Explainable-techniques/Assignment-7/Explainable_Deep_Learning_Assignment_07.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import IntegratedGradients\n",
        "from tcav import TCAV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUrb1hQaqWdU"
      },
      "outputs": [],
      "source": [
        "# Step 1: Dataset Preparation\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Assuming images of oranges and basketballs are stored in './data/oranges' and './data/basketballs'\n",
        "dataset = ImageFolder(root='./data', transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw2_uaIZqWdU"
      },
      "outputs": [],
      "source": [
        "# Step 2: Model Selection\n",
        "model = models.resnet34(pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr3x6qH5qWdV"
      },
      "outputs": [],
      "source": [
        "# Step 3: TCAV Analysis\n",
        "# Placeholder for TCAV implementation - requires concepts and bottlenecks to be defined\n",
        "# Assuming we have defined bottlenecks and concept datasets\n",
        "tcav = TCAV(model, bottlenecks, concepts, target_class)\n",
        "tcav_scores = tcav.run()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUDVvWtuqWdV"
      },
      "outputs": [],
      "source": [
        "# Step 4: Integrated Gradients\n",
        "ig = IntegratedGradients(model)\n",
        "\n",
        "def visualize_integrated_gradients(input_image, target_class):\n",
        "    input_image = input_image.unsqueeze(0)\n",
        "    input_image.requires_grad = True\n",
        "    attributions, delta = ig.attribute(input_image, target=target_class, return_convergence_delta=True)\n",
        "    attributions = attributions.squeeze().cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(attributions, (1, 2, 0)))\n",
        "    plt.title('Integrated Gradients Attribution')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with an image from the validation set\n",
        "sample_image, sample_label = val_dataset[0]\n",
        "visualize_integrated_gradients(sample_image, sample_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XweNbVmWqWdV"
      },
      "outputs": [],
      "source": [
        "# Step 5: Statistical Testing\n",
        "# Placeholder for statistical testing of TCAV scores\n",
        "import scipy.stats as stats\n",
        "t_stat, p_value = stats.ttest_ind(tcav_scores_oranges, tcav_scores_basketballs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
